\section{R-Code}
\label{sec:R-Code}

\subsection{R-Packages}
\label{sec:R-Packages}

We conduct our analysis in the statistical software R, see \textcite{R:2022}. For our data cleansing, data handling and plotting we use the \textit{tidyverse} package of \textcite{Tidyverse:2019}. Further we use the packages \textit{here} of \textcite{here:2020}, \textit{miceadds} of \textcite{Miceadds:2023} and \textit{parallel}, which is part of core R, to facilitate our analysis.  

For building our CoDA model we use the packages \textit{vars} of \textcite{VAR:2008,CoDAR2:2008} and \textit{robCompositions} of \textcite{RobComp:2011,CoDAR4:2018}. Especially the functions \texttt{pivotCoord}, which performs the $ilr$ transformation described in Section \ref{sec: Coda Preliminaries},\texttt{VAR}, which builds the VAR model described in Section \ref{sec:The VAR Model}, and \texttt{pivotCoordInv}, which performs the necessary back transformation to get predictions in the desired space. The INGARCH analysis is mainly done with the package \textit{tscount}, see \textcite{Tscount:2017,Tscount:2020}. The core function used is \texttt{tsglm}, which we use to fit the INGARCH(p,q) model as well as the log-linear model. The zero-inflated models were fitted using the function \texttt{zeroinfl} from the package \textit{pscl} of \textcite{Pscl:2008}. To fit the INAR model we use two packages. First, \textit{ZINAp} to calculate our predictions with the Bayesian approach. The function \texttt{estimate\_zinarp} is used to estimate the coefficients and the values are then calculated according to the formula in \textcite{Silva:2009}. Second, the classical approach is done using the function \texttt{EST\_ZINAR} from the package \textit{ZINA1}. % For the VGAM we used the package \textit{VGAM} of \textcite{RVGAM:2010}.

In general, all other functions can be grouped into three categories: general, count data model specific and CoDA specific. General functions are used for both, the count data models and the CoDA model. Count data models and CoDA specific functions are only used for their respective methods.
\subsection{Handbook}
\label{sec:Handbook}

In this handbook, we will describe the use and results of the most important functions used for our analysis.  The code for them can be found in the GitHub repository, see \textcite{GitHub}. 

\subsubsection{Data.Window}
\label{sec: Data.Window}
%Notable general functions are \texttt{Data.Window} and \texttt{Data.Preparation}. The former function splits the time series in the specified windows and the value to be predicted. The models are then fitted on these windows and the prediction result is compared with the actual value. The latter one brings the data in the right format, replaces missing values with 0 and accounts for the length of the history chosen. In addition, for CoDA it also transform the data into the right format needed for the one-vs-all method. Other important functions are \texttt{Model.Error} and \texttt{Model.ErrorOverall} which implement the error measure introduced in \ref{sec: Error Measure} and summarise it. 

The function \texttt{Data.Window} splits the time series in the specified windows and the value to be predicted. The models are then fitted on these windows and the prediction result can be compared with the actual value.

\textbf{Arguments}:

\begin{itemize}
	\item Timeseries: The time series to be split up in windows.
	\item Frame: The window length to split the time series into.
	\item Method: How the time series should be split up. For example if the windows should be extended at each step or be kept at a fixed length.
	\item PredictionStep: The future prediction step.
\end{itemize}

\textbf{Values}:

A list of all windows is returned. A window is a list with the following elements: 

\begin{itemize}
	\item timeSeriesValue\_window: The values of the window
	\item timeSeriesValue\_future: The value which should be predicted by this window. 
\end{itemize}

\subsubsection{Data.Preparation}
\label{sec:Data.Preparation}

The function \texttt{Data.Preparation} transforms the data in the right format, replaces missing values with 0 and accounts for the length of the history chosen. In addition, for CoDA it also transforms the data into the right format needed for the one-vs-all method.

\textbf{Arguments}:

\begin{itemize}
	\item Data\_Raw: The Data to be transformed in the right format.
  \item OneVsAll: When TRUE, then the one-vs-all method is used.
  \item PivotGroup: When one-vs-all is used, this specifies the pivot category.
  \item Category: The categories to consider for the transformation.
  \item NA\_to: The value with which NA values should be replaced with.
  \item HistoryLength: The length of the history. Can be an absolute number or a ratio $0<h\leq 1$. 
  \item TakeSubCategory: When TRUE, we transform the data for the subcategories instead of the main categories. 
\end{itemize}

\textbf{Values}:

A tibble with two or more columns is returned, depending on the number of categories: 

\begin{itemize}
	\item week\_date: The values of the window
	\item \textit{Name of Category 1}: The number of sold items belonging to \textit{Name of Category 1}.
\end{itemize}

When the argument OneVsAll is TRUE, then a tibble with three columns is returned.


\begin{itemize}
	\item week\_date: The values of the window
	\item PivotGroup: The amount of sold items belonging to the pivot group.
	\item other: The amount of all other sold items belonging to the other categories. 
\end{itemize}

\subsubsection{Model.Error}
\label{sec:Model.Error}

The function \texttt{Model.Error} calculates the specified error measure for each time series and category. Since we want to compare the performance of a method with the naive model in Section \ref{sec: Naive Random Walk}, we calculate the errors for this model as well. 

\textbf{Arguments}:

\begin{itemize}
	\item Model\_Result: The result calculated by either \texttt{Coda.Analysis} or \texttt{CountModel.Analysis}.
	\item Fnct: The error function to be used. Currently the MSE and RMSE are implemented. 
	\item Category: The categories for which the errors should be caluculated.
\end{itemize}

\textbf{Values}:

A tibble with the columns is returned: 

\begin{itemize}
	\item id: The id of the fridge.
	\item category: The category for which the error was calculated. 
	\item error: The error calculated according to the error function in the Fnct argument. 
	\item error\_naive: The value of the error function for the naive random walk model.
	\item model: The used model.  
\end{itemize}

\subsubsection{Model.ErrorOverall}
\label{sec:Model.ErrorOverall}

The function \texttt{Model.ErrorOverall} is closely related to \texttt{Model.Error}. This function calculates the error measure defined in Section \ref{sec: Error Measure}. One can decide if the error measure should be calculated over all categories or if they should be split up in subsets as in Subsection \ref{sec:Error Measure Extension}.

\textbf{Arguments}:

\begin{itemize}
	\item Error\_Result: The result of the function \texttt{Model.Error}.
	\item Fnct: Function to summarise the errors. This enables one to use different methods like the mean or median. 
	\item SplitByGroup: When TRUE, then the errors are split by groups defined in the \textit{Groups} argument. 
	\item Groups: The grouped categories over which the error should be calculated. 
	\item Category: The categories for which the error should be calculated for.
\end{itemize}

\textbf{Values}:

The result is a tibble with the columns:
\begin{itemize}
	\item id: The id of the fridge. 
	\item error: The error calculated according to the error function in the Fnct argument. 
	\item model: The used model. 
	\item group: The subsets of categories as defined in Subsection \ref{sec:Error Measure Extension}.
\end{itemize}


\subsubsection{CountModel.DataPreparation}
\label{sec:CountModel.DataPreparation}

The function \texttt{CountModel.DataPreparation} transforms the data into the right format needed to fit the count data models. At its core it uses the \texttt{Data.Preparation} function but adds the additional option to replace zero values with 1. 

\textbf{Arguments}:

\begin{itemize}
	\item Data: The data to be transformed.
	\item ZeroHandling: Method for zero handling. Currently there is no treatment or them being replaced with 1. 
	\item HistoryLength: The length of the history. Can be an absolute number or a ratio $0<h\leq 1$. 
	\item TakeSubCategory: When TRUE, we transform the data for the subcategories instead of the main categories. 
\end{itemize}

\textbf{Values}:

A tibble with two or more columns is returned, depending on the number of categories: 

\begin{itemize}
	\item week\_date: The values of the window
	\item \textit{Name of Category 1}: The number of sold items belonging to \textit{Name of Category 1}.
\end{itemize}

\subsubsection{CountModel.Prediction}
\label{sec:CountModel.Prediction}

The function \texttt{CountModel.Prediction} is the function where the model is fit and the predicted value is calculated. It uses the corresponding functions mentioned in Section \ref{sec:R-Packages} to fit the INGARCH, INAR or ZIM model for each window and predicts the next value. 

\textbf{Arguments}:

\begin{itemize}
	\item Data\_Window: The data divided into the different windows by the \texttt{Data.Window} function.
	\item Data\_WindowNoTransform: The data without zero handling divided into the different windows by the \texttt{Data.Window} function.
  \item Category: The category to predict. 
  \item PredictionStep: The prediction step.
  \item Frame: The window length.
  \item Distribution: The distribution chosen for the model. Care has to be taken, since every model can choose from a different list of distributions and its name has to be specified correctly (i.e. "`Po"' for INAR but "`poisson"' for ZIM). 
  \item Plot: For the INGARCH model, diagnostic plots can be generated. Currently not implemented.
  \item WindowMethod: Method for splitting up the time series. For example if the windows are extended at each step or kept at a fixed length.
  \item External: For INGARCH. When TRUE, external factors as in Equation (\ref{eq:Ingarch model with external effect}) are used.
  \item PastOb: For INGARCH. How many past observations should be used. Equals $p$ in Equation (\ref{eq:Ingarch model}).
  \item PastMean: For INGARCH. How many past means should be used. Equals $q$ in Equation (\ref{eq:Ingarch model}).
  \item ModelType: Model to be fit. 
\end{itemize}

\textbf{Values}:

It returns a list with two elements:

\begin{itemize}
	\item prediction: A data.frame with the predicted values and some additional information.
	\item model: A list of all the models fitted for each window. 
\end{itemize}


\subsubsection{CountModel.Analysis}
\label{sec:CountModel.Analysis}


The function \texttt{CountModel.Analysis} acts as a wrapper function to streamline and facilitate the analysis. The previously mentioned model specifications can be chosen here as well as various other options. This is the sole function which has to be used by the user. The other functions are mainly for internal use.

\textbf{Arguments}:

\begin{itemize}
	\item Data\_Raw: The raw data as extracted from the data base.
  \item Id: The ids of the fridges to be analysed.
  \item PredictionStep: The future prediction step.
  \item Distribution: The distribution chosen for the model. Care has to be taken, since every model can choose from a different list of distributions and its name has to be specified correctly (i.e. "`Po"' for INAR but "`poisson"' for ZIM).
  \item ModelType: Model to be fit. 
  \item Plot: For the INGARCH model, diagnostic plots can be generated. Currently not implemented.
  \item Category\_Main: The main categories to choose. 
  \item TakeSubCategory: When TRUE, then we transform the data for the subcategories instead of the main categories. 
  \item Category\_Sub: The sub categories to choose.
  \item Frame: The window length.
  \item WindowMethod: Method for splitting up the time series. For example if the windows are extended at each step or kept at a fixed length.
  \item ZeroHandling: Method for zero handling. Currently there is no treatment or them being replaced with 1. 
  \item PastOb: For INGARCH. How many past observations should be used. Equals $p$ in Equation (\ref{eq:Ingarch model}).
  \item PastMean: For INGARCH. How many past means should be used. Equals $q$ in Equation (\ref{eq:Ingarch model}).
  \item External: For INGARCH. When TRUE, external factors as in Equation (\ref{eq:Ingarch model with external effect}) are used.
  \item HistoryLength: The length of the history. Can be an absolute number or a ratio $0<h\leq 1$.
  \item Multicore: When TRUE, then calculations are done on multiple cores to improve performance. Internally the parallelisation takes place across the different categories to be calculated. 
  \item NCores: The number of cores to be used for parallelisation. 
\end{itemize}

\textbf{Values}:

This function returns a list with two values:

\begin{itemize}
	\item result: The analysis result in the form of a data.frame. 
	\item model: A nested list with all models, fitted for each id, category and window.
\end{itemize}

\subsubsection{Coda.DataPreparation}
\label{sec:Coda.DataPreparation}

The function \texttt{Coda.DataPreparation} is analog to CountModel.Preparation

\textbf{Arguments}:
\begin{itemize}
  \item Data: The data to be transformed.
  \item ZeroHandling: Method for zero handling.  Currently there is no treatment, the simple replacement strategy or adding 0.5 to all values. 
  \item TSpace: When TRUE, then $\Tsp$-Spaces are used.
  \item Log: When TRUE, then the logarithm of the total sum is used in the $\Tsp$-Space.
  \item OneVsAll: When TRUE, then the one-vs-all method is used.
  \item PivotGroup: When one-vs-all is used, this specifies the pivot category.
  \item HistoryLength: The length of the history. Can be an absolute number or a ratio $0<h\leq 1$.
	\item DL: The value $\delta$ for the simple replacement strategy in (\ref{eq:simple replacement strategy}). 
\end{itemize}

\textbf{Values}:

The result is a tibble. The columns are the ilr transformed data and hence the number of columns depends on the dimension of the data:

\begin{itemize}
	\item week\_date: The values of the window.
	\item \textit{Name of ilr transformed category 1}: The ilr transformed values.
\end{itemize}

If $\Tsp$-Spaces are used then an additional column with the sum or log-sum is added:

\begin{itemize}
	\item week\_date: The values of the window.
	\item \textit{Name of ilr transformed category 1}: The ilr transformed values.
	\item tsum: Either the total sum or log-sum. 
\end{itemize}

\subsubsection{Coda.Prediction}
\label{sec:Coda.Prediction}

The function \texttt{Coda.Prediction} acts like its respective count model counterpart.

\textbf{Arguments}:

\begin{itemize}
	\item Data\_Window: The data divided into the different windows by the \texttt{Data.Window} function.
	\item Data\_WindowNoTransform: The data without zero handling and no transformation divided into the different windows by the \texttt{Data.Window} function.
	\item Data\_NoTransform: The data without zero handling and no transformation.
	\item PredictionStep: The future prediction step.
	\item OneVsAll: When TRUE, then the one-vs-all method is used.
	\item TSpace: When TRUE, then $\Tsp$-Spaces are used.
	\item Log: When TRUE, then the logarithm of the total sum is used in the $\Tsp$-Space.
	\item PivotGroup: When one-vs-all is used, this specifies the pivot category.
	\item Frame: The window length.
\end{itemize}

\textbf{Values}:

It returns a list with two elements:

\begin{itemize}
	\item prediction: A data.frame with the predicted values and some additional information.
	\item model: A list of all the models fitted for each window. 
\end{itemize}

\subsubsection{Coda.Analysis}
\label{sec:Coda.Analysis}

Again \texttt{Coda.Analysis} is the wrapper function. This is again the only function which needs to be used by the user to fit models for the specified time series.

\textbf{Arguments}:

\begin{itemize}
	\item Data\_Raw: The raw data as extracted from the data base.
	\item Id: The ids of the fridges to be analysed.
	\item Frame: The window length.
	\item ZeroHandling: Method for zero handling. 
	\item PredictionStep: The future prediction step. 
	\item Log: When TRUE, then the logarithm of the total sum is used in the $\Tsp$-Space.
	\item TSpace: When TRUE, then $\Tsp$-Spaces are used. 
	\item OneVsAll: When TRUE, then the one-vs-all method is used. 
	\item PivotGroup: When one-vs-all is used, this specifies the pivot category.
	\item HistoryLength: The length of the history. Can be an absolute number or a ratio $0<h\leq 1$. 
	\item ModelType: Model to be fit. Currently only ``coda'' and ``coda\_OneVsAll'' can be chosen.
	\item WindowMethod: Method for splitting up the time series. For example if the windows are extended at each step or kept at a fixed length.
	\item DL: The value $\delta$ for the simple replacement strategy in (\ref{eq:simple replacement strategy}). 
\end{itemize}

\textbf{Values}:

This function returns a list with two values:

\begin{itemize}
	\item result: The analysis result in the form of a data.frame. 
	\item model: A nested list with all models, fitted for each id, category and window.
\end{itemize}


