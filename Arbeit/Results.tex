\section{Results}
\label{sec:Results}

In this section we present and describe the results for our methods with their variations. For this we use the previously introduced error measure, calculate it for all available fridges and summarise the results. We show the results as graphics for easier interpretation. Since we focus on the CoDA and INGARCH models, we only present the in detail results for them. For a general comparison, the ZIM and INAR model are included as well. 

\subsection{Model Comparison}
\label{sec: Model Comparison}

Here we compare the INGARCH(1,1) model with the CoDA and INAR(1) model. For all three models we use the same parameter values, namely a window factor of $w=0.5$, the whole history $h=1$ and extending windows. For CoDA, the settings are no $\Tsp$-Space, one-vs-all method and the simple replacement strategy with $\delta=0.1$. For INGARCH(p,q) we use $p=q=1$, assume it is Poisson distributed, use no external factors and have no zero handling. For INAR(1) we use the classical forecasting method described in section \ref{sec: Inar Parameter Estimation and Forecasting}. When we speak of standard settings or values in the following, we mean these settings. 

In figure \ref{fig:models Comp1} we see a boxplot and quantile plot. In the boxplot the error measure is calculated for all groups and all fridges for each model. The result is then shown in a boxplot. In the quantile plot, the error measure for each fridge, each model and each category is calculated and sorted according to their size. The dot size indicates the length of the respective time series and the vertical lines are the 0\%,25\%,50\%,75\% and 100\% quantile.

In the boxplot \ref{fig:box distributions models} we can see that their performance is pretty similar. They all seem to outperform the the naive random walk model, which is especially true for the count data models. 
In the quantile plot \ref{fig: quantile distributions models} we see the error measure split up by category. While for category 1 and 2 all models perform reasonable well and similar, differences emerge for category 3 and 4. CoDA seems to be the clear favourite in category 4, followed by INGARCH and then INAR. However, for all models there are again time series with errors that are either too high to be shown, or that couldn't get calculated at all. 
\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{All_ErrorMeasure_combined_zoomed_ZIMFALSE.png}
\caption{Boxplot for the different models}
\label{fig:box distributions models}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{Quantile_Plot_Split_all_models_ZIMFALSE.png}
\caption{Quantiles for the different models}
\label{fig: quantile distributions models}
\end{subfigure}
\hfill
\caption{Comparison of the different models}
\label{fig:models Comp1}
\end{figure}

In figure \ref{fig:models Comp2} we also include the ZIM model. One drawback about the ZIM model is, that it needs to have zero values in the fitted window. Because of the lack of them in category 1 and 2, we couldn't manage to fit it. Hence the models in \ref{fig:models Comp2} were only fitted on categories 3 and 4. 

In \ref{fig:box distributions models Zim} we again see the boxplot for the summarised error. The ZIM is close to INGARCH, but all three models still lag behind CoDA. In \ref{fig: quantile distributions models Zim} we see again the error measure for each category. While the models perform similar for category 3, the CoDA still outperforms all models for category 4. Here it is worth mentioning, that category 4 is the main category with the most amount of zeros in our data. It should be mentioned here, that all models don't predict integer values, but rather real values which then get rounded to the nearest integer value. Especially CoDA cannot predict zero values but only small positive values which get rounded to zero.

\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{All_ErrorMeasure_combined_zoomed_ZIMTRUE.png}
\caption{Boxplot for the different models}
\label{fig:box distributions models Zim}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{Quantile_Plot_Split_all_models_ZIMTRUE.png}
\caption{Quantiles for the different models}
\label{fig: quantile distributions models Zim}
\end{subfigure}
\hfill
\caption{Comparison of the different models }
\label{fig:models Comp2}
\end{figure}

%To further investigate the struggles of CoDA and INAR we look in detail at the time series with the highest error measures. The fridge with the highest error is 100402 \ref{fig:CodaIngarchInar_Timeseries_ID100402}. We can see that in category 4 for both, INAR and Coda, the predictions stay at 1, even after a repeated amount of zero values. INGARCH on the other hand, starts to predict zero values after two time points. While the absolute difference is only one, the error measure is so high because the naive random walk model predicts all values correctly as zero and therefore the nominator in equation \ref{eq: Error Measure Subsets} is theoretically zero. In practice, we implemented a fail-safe and set the nominator to 1e-6 to avoid division by 0. 
%\begin{figure}[htbp]
	%\centering
		%\includegraphics[width=0.80\textwidth]{Graphiken/CodaIngarchInar_Timeseries_ID100402.png}
	%\caption{Time series for fridge 100402}
	%\label{fig:CodaIngarchInar_Timeseries_ID100402}
%\end{figure}
%
%The second highest error for CoDA is for fridge 100403 \ref{fig:CodaIngarchInar_Timeseries_ID100403}. Again, we only have zero values for category 4 but this time non of the methods predicts zero values. The same reasoning as above can be used to explain the high error value. 
%
%\begin{figure}[htbp]
	%\centering
		%\includegraphics[width=0.80\textwidth]{Graphiken/CodaIngarchInar_Timeseries_ID100403.png}
	%\caption{Time series for fridge 100403}
	%\label{fig:CodaIngarchInar_Timeseries_ID100403}
%\end{figure}
%
%The same thing happens for time series 100191. We have an excessive amount of zero values and CoDA fails to adapt to this while INGARCH and INAR both start to predict zero after some time.
%
%\begin{figure}[htbp]
	%\centering
		%\includegraphics[width=0.80\textwidth]{Graphiken/CodaIngarchInar_Timeseries_ID100191.png}
	%\caption{Time series for fridge 100191}
	%\label{fig:CodaIngarchInar_Timeseries_ID100191}
%\end{figure}
%
%This shows that the CoDA methodolgy seems to struggle with an excessive amount of zero values.

\subsection{General Specifications}
\label{sec:General Specifications}

First, we start with specifications which can be chosen for both CoDA and INGARCH. We will always vary one parameter, while using the respective standard values for the other parameters. 
\subsubsection{History}
\label{sec:History}

As mentioned various times throughout this thesis, the the history is one of the parameters which can be adjusted. In figure \ref{fig:History Comp1} we visualise the results as a boxplot, a quantile plot  and additionally an histogram to get a feeling for the error distribution. 

\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Box_all__Variation_history.png}
\caption{Boxplot of different $h$}
\label{fig:History Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Histogram_all__Variation_history.png}
\caption{Histogram of different $h$}
\label{fig:History Hist}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Quant_all__Variation_history.png}
\caption{Quantiles Plot of different $h$}
\label{fig:History Quant}
\end{subfigure}
\caption{Comparison of different $h$}
\label{fig:History Comp1}
\end{figure}

In figure \ref{fig:History Comp1} we can see that the results for CoDA do not vary too much for the different histories. However, one can see in the quantile plot \ref{fig:History Quant} that we have 8 less values for  $h=0.5$ than for $h=1$. This probably results from the fact, that if we only take half of the history for an already short time series, then we have too little values for estimating. 

For INGARCH, the results are similar as well. For $h=1$ we get slightly higher values for the error measure as seen in \ref{fig:History Box}. But again in \ref{fig:History Quant} we see that we have less values for the shorter history for the same reason as above. 

\subsubsection{Frame}
\label{sec:Frame}

Next, we vary the initial frame length $w_f$. We choose to extend the frame with each new data point. For this we vary the value $w$ in $w_f=w\cdot T$. The results are portrayed in \ref{fig:Frame Comp1}. In general, there is not much difference between the different frames. INGARCH seems to perform better for all three values.
\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Box_all__Variation_frame.png}
\caption{Boxplot of different $w$}
\label{fig:Frame Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Histogram_all__Variation_frame.png}
\caption{Histogram of different $w$}
\label{fig:Frame Hist}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Quant_all__Variation_frame.png}
\caption{Quantiles of different $w$}
\label{fig:Frame Quant}
\end{subfigure}
\caption{Comparison of different $w$}
\label{fig:Frame Comp1}
\end{figure}


In the boxplot \ref{fig:Frame Box} it looks like INGARCH performs worst for $w=0.5$. However, in the quantile plot \ref{fig:Frame Quant} we can see that for $w=0.3,0.7$ the last errors are not included  in the plot. This could either be a result of them being to high, or that the model couldn't be fit on those fridges. 

For CoDA there seems not to be much difference. The best results are obtained with $w=0.3$, but the differences are only marginal. 


\subsubsection{Window Shape}
\label{sec:Window Shape}

We also vary the shape of the window. As explained in \ref{sec: Model Specification} we either use a fixed amount of points and add and remove points as time goes on, or we continuously add points to the window. The results are in figures \ref{fig:window methods Comp1}. We can see that there are no big differences between the methods. For both, CoDA and INGARCH, there are no notable difference. 

\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Box_all__Variation_windowMethod.png}
\caption{Boxplot for different window shapes}
\label{fig:window methods Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Histogram_all__Variation_windowMethod.png}
\caption{Histogram for different window shapes}
\label{fig:window methods Hist}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCombined_Quant_all__Variation_windowMethod.png}
\caption{Quantiles for different window shapes}
\label{fig:window methods Quant}
\end{subfigure}
\caption{Comparison of different window shapes}
\label{fig:window methods Comp1}
\end{figure}


\subsection{INGARCH Specifications Results}
\label{sec: Ingarch Specifications Results}

Next we will investigate the INGARCH specific options. As before, we use the standard settings for the INGARCH(1,1) model and always vary one parameter. 

\subsubsection{Distribution}
\label{sec:Distribution}

As mentioned in section \ref{sec: Ingarch Specifications} we can replace the Poisson distribution with a Negative Binomial Distribution in \ref{eq:Ingarch Distribution}. The results are shown in figure \ref{fig:distributions Comp1}. 

\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Box_all__Variation_distribution.png}
\caption{Boxplot for different distributions}
\label{fig:distributions Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Histogram_all__Variation_distribution.png}
\caption{Histogram for different distributions}
\label{fig:distributions Hist}
\end{subfigure}
\hfill
%\begin{subfigure}[b]{0.8\textwidth}
%\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Quant_all__Variation_windowMethod.png}
%\caption{Quantiles for different distributions}
%\label{fig:window methods Quant}
%\end{subfigure}
\caption{Comparison of different distributions}
\label{fig:distributions Comp1}
\end{figure}

As we can see, we get the exactly the same results for both distributions. However, as mentioned in section \ref{sec: Estimation of the Ingarch Model}, we round the predicted conditional mean to the next integer. Hence, we could get slightly different results for the different distributions. Nevertheless, the difference is still negligible. %Since the Poisson Distribution is a limiting case of the Negative Binomial Distribution when $\phi \longrightarrow \infty$ in \ref{eq:Ingarch negbinom Distribution}, \cite{Liboschik:2016}. 


\subsubsection{Number of Past Means and Observations}
\label{sec: Number of Past Means and Observations}

The order in the INGARCH(p,q) model is another parameter which can be chosen. For simplicities sake we only compare our INGARCH(1,1) with an INGARCH(1,2) and INGARCH(2,1) model. However, further models could be tried out and compared. 

In figure \ref{fig:past means Comp1} we compare the INGARCH(1,1) model (red) with the INGARCH(1,2) model (blue). We can see that the performance is very similar. Hence we prefer the smaller model. 
\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Box_all__Variation_pastMean.png}
\caption{Boxplot for a different number of past means}
\label{fig:past means Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Histogram_all__Variation_pastMean.png}
\caption{Histogram for a different number of past means}
\label{fig:past means Hist}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Quant_all__Variation_pastMean.png}
\caption{Quantiles for a different number of past means}
\label{fig:past means Quant}
\end{subfigure}
\caption{Comparison of a different number of past means}
\label{fig:past means Comp1}
\end{figure}


In figure \ref{fig:past obs Comp1} we compare the INGARCH(1,1) (red) model with the INGARCH(2,1) (blue) model. Again the performance is very similar in general. 

\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Box_all__Variation_pastOb.png}
\caption{Boxplot for a different number of past observations}
\label{fig:past obs Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Histogram_all__Variation_pastOb.png}
\caption{Histogram for a different number of past observations}
\label{fig:past obs Hist}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureINGARCH_Quant_all__Variation_pastOb.png}
\caption{Quantiles for a different number of past observations}
\label{fig:past obs Quant}
\end{subfigure}
\caption{Comparison of a different number of past observations}
\label{fig:past obs Comp1}
\end{figure}

As we saw, there is not much difference between the INGARCH(1,1), INGARCH(2,1) and INGARCH(1,2) model. One could compare the AIC or some other measure for the different models and base their choice on that. However, this is not further explored here and hence the INGARCH(1,1) model is taken because it is the smallest.

\subsection{CoDA Specifications Results}
\label{sec: CoDA Specifications Results}

Last, we will compare different CoDA Specifications as mentioned in section \ref{sec: Coda Specifications}. Like above we choose one standard model for comparison and always only change one setting. For CoDA our standard model uses extending windows, the full history $h=1$, an initial window length of $w=0.5$, use the simple replacement strategy with $\delta=0.1$, no $\Tsp$-spaces and the one-vs-all method. 

\subsection{Zero Handling}
\label{sec: Zero Handling}

First we compare the different options of handling zeros as explained in section \ref{sec: Coda Specifications}. The results are shown in figure \ref{fig:Coda zero handling Comp1}. It seems that the simple replacement strategy with $\delta_j = 0.1$, $\forall j$ results in marginally better performance.

\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Box_all__Variation_zeroHandling.png}
\caption{Boxplot for a different methods of zero handling}
\label{fig:Coda zero handling Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Histogram_all__Variation_zeroHandling.png}
\caption{Histogram for a different methods of zero handling}
\label{fig:Coda zero handling Hist}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Quant_all__Variation_zeroHandling.png}
\caption{Quantiles for a different methods of zero handling}
\label{fig:Coda zero handling Quant}
\end{subfigure}
\caption{Comparison of different zero handling methods}
\label{fig:Coda zero handling Comp1}
\end{figure}

For the simple replacement strategy, one can also vary the parameter $\delta$. In figure \ref{fig:ErrorMeasureCoDA_Box_all__Variation_dL} we plotted the results for $\delta=0.01,0.1,0.5$. While the difference don't seem big at first, when we calculate the error measure only for category 4, the category with most zeros, we can see a drastic rise in performance \ref{fig:ErrorMeasureCoDA_Box_all__Variation_dLcat4}. For smaller values of $\delta$ we get better results. 

%One possible remedy to this problem is to vary the value of $\delta$ in the simple replacement method \ref{eq:simple replacement strategy}. While for the above results we used $\delta = 0.5$, in figure \ref{fig:ErrorMeasureCoDA_Box_all__Variation_dLcat4} one can see that we get considerable better results if we use a smaller $\delta$ value. With those configurations, CoDA predicts zero values faster than before however, the difference in total is not huge as seen in figure \ref{fig:ErrorMeasureCoDA_Box_all__Variation_dL} since after all, the absolute difference is only 1 in most cases.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.80\textwidth]{Graphiken/ErrorMeasureCoDA_Box_all__Variation_dL.png}
	\caption{Error Measure for all categories}
	\label{fig:ErrorMeasureCoDA_Box_all__Variation_dL}
\end{figure}

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.80\textwidth]{Graphiken/ErrorMeasureCoDA_Box_all__Variation_dLcat4.png}
	\caption{Error Measure for Category 4}
	\label{fig:ErrorMeasureCoDA_Box_all__Variation_dLcat4}
\end{figure}



To further investigate the differences, we look in detail at the time series with the highest error measures for $\delta=0.5$. The fridge with the highest error is 100402, shown in figure \ref{fig:Coda_Timeseries_ID100402}. We can see that for $\delta=0.5$ in category 4, the predictions stay at 1, even after a repeated amount of zero values. With the smaller $\delta$-values on the other hand, CoDA starts to predict zero values after one or two time points. While the absolute difference is only one, the error measure is so high because the naive random walk model predicts all values correctly as zero and therefore the nominator in equation \ref{eq: Error Measure Subsets} is theoretically zero. In practice, we implemented a fail-safe and set the nominator to 1e-6 to avoid division by 0. 


\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.80\textwidth]{Graphiken/Coda_Timeseries_VariationdL100402.png}
	\caption{Time series for fridge 100402}
	\label{fig:Coda_Timeseries_ID100402}
\end{figure}

The second highest error for CoDA is for fridge 100403, shown in \ref{fig:Coda_Timeseries_ID100403}. Again, we only have zero values for category 4 and for $\delta=0.5$ CoDA never predicts zero. The same reasoning as above can be used to explain the high error value. 

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.80\textwidth]{Graphiken/Coda_Timeseries_VariationdL100403.png}
	\caption{Time series for fridge 100403}
	\label{fig:Coda_Timeseries_ID100403}
\end{figure}

The same thing happens for time series 100191 in figure \ref{fig:Coda_Timeseries_ID100191}. We have an excessive amount of zero values and if $\delta$ is too high, CoDA fails to predict the correct value. 

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.80\textwidth]{Graphiken/Coda_Timeseries_VariationdL100191.png}
	\caption{Time series for fridge 100191}
	\label{fig:Coda_Timeseries_ID100191}
\end{figure}

One thing that stands out in these time series is, that for categories 1 and 2, the predicted values are the same for all three values of $\delta$. 

\subsection{$\Tsp$-spaces}
\label{sec: Tspaces results}

Next we compare CoDA for $\Tsp-$Spaces. The results are shown in \ref{fig:Coda T-Spaces Comp1}. It seems that using no $\Tsp-$Spaces result in slightly better results. Especially for shorter time series using no $\Tsp-$Spaces returns better results. This can be seen in figure \ref{fig:Coda T-Spaces Quant}

\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Box_all__Variation_tSpace.png}
\caption{Boxplot for $\Tsp-$Spaces}
\label{fig:Coda T-Spaces Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Histogram_all__Variation_tSpace.png}
\caption{Histogram for $\Tsp-$Spaces}
\label{fig:Coda T-Spaces Hist}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Quant_all__Variation_tSpace.png}
\caption{Quantiles for $\Tsp-$Spaces}
\label{fig:Coda T-Spaces Quant}
\end{subfigure}
\caption{Comparison of CoDA with and without $\Tsp-$Spaces}
\label{fig:Coda T-Spaces Comp1}
\end{figure}

To further investigate the reason of this difference in performance, we picked out the two time series with the highest error. The fridge with the highest error had Id 100321. Its time series can be seen in figure \ref{fig:Coda_Timeseries_VariationtSpace100321}. As we can seen, CoDA with $\Tsp$-Spaces performs worse for category 1 and 2. However, the time series is also short by nature with only 14 recorded points in time.  

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.80\textwidth]{Graphiken/Coda_Timeseries_VariationtSpace100321.png}
	\caption{Time series of fridge 100321}
	\label{fig:Coda_Timeseries_VariationtSpace100321}
\end{figure}

The second highest error measure has fridge 20, shown in \ref{fig:Coda_Timeseries_VariationtSpace20}. Again, the problem lies in category 1 and 2. Especially for category 1, CoDA with $\Tsp$-Space seems to continuously underestimate the true values. For category 3 and 4, both settings have very similar results.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.80\textwidth]{Graphiken/Coda_Timeseries_VariationtSpace20.png}
	\caption{Time series of fridge 20}
	\label{fig:Coda_Timeseries_VariationtSpace20}
\end{figure}

\subsection{One-vs-All method}
\label{sec: One-vs-All}

Now we analyse the one-vs-all method. Figure \ref{fig:Coda One-vs-All Comp1} shows the results. We can clearly seen, that the one-vs-all method performs better over all time series. This difference is highlighted in figure \ref{fig:Coda One-vs-All Quant}. 

\begin{figure}[htb!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Box_all__Variation_oneVSAll.png}
\caption{Boxplot for One-vs-All}
\label{fig:Coda One-vs-All Box}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Histogram_all__Variation_oneVSAll.png}
\caption{Histogram for One-vs-All}
\label{fig:Coda One-vs-All Hist}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.8\textwidth}
\includegraphics[width=\textwidth]{ErrorMeasureCoDA_Quant_all__Variation_oneVSAll.png}
\caption{Quantiles for One-vs-All}
\label{fig:Coda One-vs-All Quant}
\end{subfigure}
\caption{Comparison of CoDA with and without One-vs-All}
\label{fig:Coda One-vs-All Comp1}
\end{figure}

















