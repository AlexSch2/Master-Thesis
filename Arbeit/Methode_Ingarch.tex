\section{INGARCH}
\label{sec:Ingarch}

In this section we introduce the INGARCH(p,q) model. First we provide a motivation on why we chose this model and review some other possible models for discrete time series count data. The review is mainly based on \cite{Liboschik:2016} and \cite{Heinen:2003}. A more detailed review can be found in \cite{Zucchini:1997}. Subsequently we define the INGARCH(p,q) model itself and list some of its properties. 

\subsection{Motivation}
\label{sec:Ingarch Motivation}

This section is based on \cite{Liboschik:2016} and \cite{Heinen:2003}. \newline
Since our data can be seen as a discrete time series with count data, we want a model which is able to take these properties into account. In addition, autocorrelation and overdispersion are two common features in count data.  
One common way to deal with count data are Markov chains. The dependent variable can take on all possible values in the so called state space and the probability of changing states is then modelled as a transition probability. A limitation is the fact that these models become cumbersome if the state space gets too big and lose tractability. As an extension to the basic Markov chains models, Hidden Markov chains are proposed by \cite{Zucchini:1997}. However, since there is no generally accepted way to determine the order of this model, it can cause problems if the data structure does not provide intuitive ways to do it. Another issue is that the number of parameters which need to be estimated gets big quickly, especially if the order of the model is big. 

Other common models for time series data are the ARMA models. There exists a discrete version of them in the form of the Discrete Autoregressive Moving Average (DARMA) models. They can be defined as a mixture of discrete probability distributions and a suitable chosen marginal probability function \cite{Biswas:2009}. While there have been various applications, for example in \cite{Chang:1987}, there seem to be difficulties in their estimation \cite{Heinen:2003}. 

State space models with conjugated priors are proposed by \cite{Harvey:1989}. The observations are assumed to be drawn from a Poisson distribution whose mean itself follows a Gamma distribution. The parameters of the Gamma distribution are chosen in such a way that its mean is constant but its variance is increasing. While there are ways proposed by \cite{Qaqish:1988} to handle overdispersion, these models have the weakness of needing further assumptions to handle zeros while also having more complicated model specifications \cite{Heinen:2003}.

While there are many more possible models, we decided to focus on the class of Generalised Linear Models (GLM). In the case of discrete time series with count data, the observations are modelled conditionally on the past and follow a discrete distribution. The conditional mean is then connected with a link function to the past observations and conditional means. Furthermore, a covariate vector can be introduced to account for external influence. While being easy to use and estimate they still provide a good amount of flexibility. In addition, a wide array of tools is available for various tests and forecasts. From the class of the GLMs we compare the INGARCH(p,q) and a log-linear model, which will be discussed in section \ref{sec: Other methods}. We then chose the INGARCH(p,q) model based on its superior performance and stability.


\subsection{INGARCH Model}
\label{sec:Ingarch Model}
Take again our time series $\left\{\bm{Y}_t:t\in \mathbb{N}, \bm{Y}_t \in \mathbb{N}_0^K \right\}_f$ for fridge $f$ and denote the univariate time series for category $k$ with $\left\{Y_{k_t}:t\in \mathbb{N}, Y_{k_t} \in \mathbb{N}_0\right\}_f$  for $k=1,\ldots,K$. Denote a r-dimensional time varying covariate vector with $\textbf{X}_t=(X_{t,1},\ldots,X_{t,r})^T$. Let the conditional mean be $\lambda_t = \mathbb{E}\left[Y_{k_t} | \SigA_{t-1} \right]$ where $\SigA_{t-1}$ is the sigma-field generated by $Y_{k_t}$ and $\lambda_l$ for $l<t$ $, \SigA _{t-1}= \sigma(Y_{k_1},\ldots,Y_{k_l},\lambda_1, \ldots, \lambda_l)$. Therefore, the conditional mean of the time series is dependent on its combined history of the past conditional means and its past values. With this, we can define the integer valued generalized autoregressive conditional heteroskedasticity model of order (p,q) (INGARCH(p,q) model) as,

\begin{gather}
\label{eq:Ingarch model}
Y_{k_t} | \SigA_{t-1} \sim P(\lambda_t); \forall t \in \mathbb{N}, \\
\mathbb{E}\left[Y_{k_t} | \SigA_{t-1} \right] = \lambda_t = \beta_0 + \sum_{i=1}^p\beta_i Y_{k_{t-i}} + \sum_{j=1}^q\alpha_j \lambda_{t-j}
\end{gather}

where $p,q \in \mathbb{N}$ and $P(\lambda_t)$ is a Poisson distribution with mean $\lambda_t$. The integer $p$ defines the number of past values to regress on, whereas $q$ does the same for the past conditional means. In order to account for external effects as well, we add the covariate vector $\textbf{X}_t$

\begin{gather}
\label{eq:Ingarch model with external effect}
Y_{k_t} | \SigA_{t-1} \sim P(\lambda_t); \forall t \in \mathbb{N}, \\
\mathbb{E}\left[Y_{k_t} | \SigA_{t-1} \right] = \lambda_t = \beta_0 + \sum_{i=1}^p\beta_i Y_{k_{t-i}} + \sum_{j=1}^q\alpha_j \lambda_{t-j} + \bm{\eta}^T\textbf{X}_t
\end{gather}

where $\bm{\eta}$ is the parameter for the covariates. 

The distributional assumptions $Y_{k_t} | \SigA_{t-1} \sim P(\lambda_t)$ implies 

\begin{equation}
p_t(y;\bm{\theta})=\mathbb{P}(Y_{k_t}=y | \SigA_{t-1}) = \frac{\lambda_t^y \exp(-\lambda_t)}{y!}, \hspace{0.2cm} y \in \mathbb{N}_0.
\label{eq:Ingarch Distribution}
\end{equation}

Furthermore it can be shown that conditionally on the past history $\SigA_{t-1}$ the model is equidispersed, i.e. it holds $\lambda_t = \mathbb{E}\left[Y_{k_t} | \SigA_{t-1}\right] = \mathbb{V}\left[Y_{k_t} | \SigA_{t-1}\right]$. However, unconditionally the model exhibits overdispersion. In that case it holds $\mathbb{E}\left[Y_{k_t}\right] \leq \mathbb{V}\left[Y_{k_t}\right] $ \cite{Heinen:2003}. 

\subsubsection{Estimation of the INGARCH Model}
\label{sec: Estimation of the Ingarch Model}

We summarise the estimation of the INGARCH(p,q) Model as described in \cite{Liboschik:2016}.

The parameter space for the INGARCH(p,q) model with external effects \ref{eq:Ingarch model with external effect} is given by 

\begin{equation*}
\Theta = \left\{ \bm{\theta} \in \mathbb{R}^{p+q+r+1}: \beta_0 > 0, \beta_1,\ldots,\beta_p,\alpha_1,\ldots,\alpha_q,\eta_1,\ldots,\eta_r \geq 0, \sum_{i=1}^p\beta_i + \sum_{j=1}^q\alpha_j < 1 \right\}.
\label{eq:Ingarch parameter space}
\end{equation*}

To ensure positivity of the conditional mean $\lambda_t$, the intercept $\beta_0$ must be positive while all other parameters must be non negative. The upper bound of the sum ensures that the model has a stationary and ergodic solution with moments of any order \cite{Ferland:2006,Fokianos:2009,Doukhan:2012}. A quasi maximum likelihood approach is used to estimate the parameters $\bm{\theta}$. 
For observations $\textbf{y} = \left(y_1,\ldots,y_n\right)^T$ the conditional quasi log-likelihood function, up to a constant, is given by,

\begin{equation}
\loglik(\bm{\theta}) = \sum_{t=1}^n\log p_t(y_t;\bm{\theta}) = \sum_{t=1}^n \left(y_t\log(\lambda_t(\bm{\theta})) - \lambda_t{\theta}\right).
\label{eq: Quasi log likelihood}
\end{equation}

where $p_t(y_t;\bm{\theta})$ is the probability density function defined in \ref{eq:Ingarch Distribution}. The conditional mean is seen as a function $\lambda_t: \Theta \rightarrow \mathbb{R}^{+}$. The conditional score function is given by,

\begin{equation}
S_n(\bm{\theta}) = \frac{\partial \loglik(\bm{\theta})}{\partial \bm{\theta}} = \sum_{t=1}^n\left(\frac{y_t}{\lambda_t(\bm{\theta})}-1\right)\frac{\partial\lambda_t(\bm{\theta})}{\partial \bm{\theta}}.
\label{eq:conditional score}
\end{equation}

The vector $\frac{\partial\lambda_t(\bm{\theta})}{\partial \bm{\theta}}$ can be computed recursively. 
The conditional information matrix is given by, 

\begin{align*}
G_n(\theta) &= \sum_{t=1}^n Cov\left(\frac{\partial \loglik(\bm{\theta}; Y_{k_t})}{\partial \bm{\theta}} \middle| \SigA_{t-1}\right) \\
&=  \sum_{t=1}^n \left(\frac{1}{\lambda_t\left(\bm{\theta}\right)}\right) \left(\frac{\partial \lambda_t(\bm{\theta})}{\partial \bm{\theta}}\right)\left(\frac{\partial \lambda_t(\bm{\theta})}{\partial \bm{\theta}}\right)^T.
\label{eq:conditional information matrix}
\end{align*}

Finally, assuming that the quasi maximum likelihood estimator (QMLE) $\hat{\bm{\theta}}_n$ of $\bm{\theta}$ exists, it is the solution to 

\begin{equation}
\hat{\bm{\theta}}:= \hat{\bm{\theta}}_n = \text{arg max}_{\bm{\theta} \in \Theta} (\loglik(\bm{\theta})). 
\label{eq:ingarch qmle}
\end{equation}
